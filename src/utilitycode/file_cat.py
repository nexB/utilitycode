#!/usr/bin/env python
# -*- coding: utf8 -*-

# ============================================================================
#  Copyright (c) nexB Inc. http://www.nexb.com/ - All rights reserved.
#  Licensed under the Apache License, Version 2.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#      http://www.apache.org/licenses/LICENSE-2.0
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#
#  SPDX-License-Identifier: Apache-2.0
# ============================================================================

import csv
import os
import sys

import click
from openpyxl import load_workbook

from utilitycode import bom_utils, file_cat_resource


@click.command()
@click.argument('input',
                required=True,
                metavar='INPUT',
                type=click.Path(
                    exists=True, file_okay=True, dir_okay=True, readable=True,
                    resolve_path=True))
@click.argument('output',
                required=True,
                metavar='OUTPUT',
                type=click.Path(
                    file_okay=False, dir_okay=True, writable=True,
                    resolve_path=True))
@click.option('--rules', type=click.Path(exists=True, file_okay=True,
                                         dir_okay=False),
              help='Path to the custom file_cat_rules.csv')
@click.option(
    '-ws', '--worksheet', nargs=1,
    help='Define the name of the worksheet to work on.'
)
@click.help_option('-h', '--help')
def cli(input, output, rules, worksheet):
    """
    Categorize the records in the .xlsx file(s) generated by the sctk2inv
    or scio2inv utility, and identify the analysis priority based on the
    rules (file_cat_rules.csv).

    Requires seven columns in the input .xlsx: 'path', 'name', 'extension',
    'mime_type', 'file_type', 'type' and 'programming_language'.
    Additional columns and their values will be preserved and included in
    the output.

    The output file will be created in the user-defined OUTPUT location,
    using the input file's basename appended with "-file-cat.xlsx".

    Sample test command:

    file-cat <path to SCTK/scan2inv input .xlsx> <path to output directory>
    file-cat <path to input directory> <path to output directory>
    """
    # Check if the output dictory exist
    if not os.path.exists(output):
        if '.' in os.path.basename(output):
            print("The output is not pointing to a directory, or " +
                  "the output directory does not exist: " + output)
        else:
            print("The ouput directory does not exist: " + output)
        sys.exit(1)

    # Read the file_cat_rules.csv and convert it to a list of dictionaries
    if rules:
        file_cat_rules_csv = rules
    else:
        file_cat_rules_csv = os.path.join(os.path.dirname(
            os.path.abspath(__file__)), "file_cat_rules.csv")
    rules_list = []

    with open(file_cat_rules_csv, mode='r', newline='', encoding='utf-8') as file:
        reader = csv.DictReader(file)
        for row in reader:
            rules_list.append(row)

    if os.path.isdir(input):
        for root, _dirs, files in os.walk(input):
            total = len(files)
            for index, file in enumerate(files):
                index = index + 1
                if file.endswith(".xlsx"):
                    input_file = os.path.join(root, file)
                    print(str(index) + "/" + str(total) +
                          " . Working on: " + file)
                    # 'results' is a list of dictionaries, with each
                    # dictionary representing a row in the input .xlsx
                    # 'headers' is a list of the column names in the input
                    # .xlsx
                    results, headers = bom_utils.get_data_from_xlsx(
                        input_file, worksheet)
                    if not worksheet:
                        worksheet_name = load_workbook(input_file).active.title
                    else:
                        worksheet_name = worksheet
                    validate_required_input_columns(headers)
                    processed_rows = process(results, rules_list)
                    output_filename = str(file).partition(
                        ".xlsx")[0] + "-file-cat.xlsx"
                    output_file = os.path.join(output, output_filename)
                    create_output_bom(headers, processed_rows,
                                      input_file, output_file, worksheet_name)
    else:
        if not input.endswith('.xlsx'):
            print(
                '\nfile-cat requires that the input be a .xlsx file -- your input is not a .xlsx file.\n')
            sys.exit(1)

        results, headers = bom_utils.get_data_from_xlsx(input, worksheet)
        if not worksheet:
            worksheet_name = load_workbook(input).active.title
        else:
            worksheet_name = worksheet
        validate_required_input_columns(headers)
        processed_rows = process(results, rules_list)

        output_filename = os.path.basename(input).partition(".xlsx")[
            0] + "-file-cat.xlsx"
        output_file = os.path.join(output, output_filename)
        create_output_bom(headers, processed_rows, input,
                          output_file, worksheet_name)


def process(results, rules_list):
    # 'resources' is a list of Resource objects representing a row in the
    # input .xlsx
    resources = [file_cat_resource.Resource.from_dict(
        result) for result in results]

    # Run the Resource objects through the rules
    processed_resources = apply_categorize_rules_results(resources, rules_list)

    # Convert the Resource objects back to dictionaries
    processed_rows = [resource.to_dict() for resource in processed_resources]
    return processed_rows


def validate_required_input_columns(headers):
    """
    Check whether the input file is missing any of the required input
    column names.
    """
    file_cat_input_headers = [
        'path', 'name', 'extension', 'mime_type', 'file_type', 'type',
        'programming_language'
    ]
    missing_input_headers = [
        i for i in file_cat_input_headers if i not in headers]

    if not len(missing_input_headers) == 0:
        print('\nYour input file is missing one or more required columns: \n\n{}\n'.
              format('\n'.join(map(str, missing_input_headers))))
        sys.exit(1)


def create_output_bom(headers, processed_rows, input, output, worksheet_name):
    """
    Validate required input columns, add any missing columns required for
    file-cat data in output file, and write output file to 'output'
    location.
    """
    # If the input file is missing any of the columns needed by the output
    # file for file-cat data, add them and apply defined order to all
    file_cat_output_headers = ['analysis_priority',
                               'file_category', 'file_subcategory']
    count = 0
    for header in file_cat_output_headers:
        if header in headers:
            headers.remove(header)
        headers.insert(count, header)
        count += 1

    output_data = []
    output_data.append(headers)
    for dict in processed_rows:
        row = []
        for field in headers:
            if field in dict:
                row.append(dict[field])
            else:
                row.append("")
        output_data.append(row)

    output_wb = load_workbook(input)

    # Get all worksheet names
    sheet_names = output_wb.sheetnames
    if worksheet_name in sheet_names:
        # Remove the existing "RESOURCES" worksheet
        output_wb.remove(output_wb[worksheet_name])
    output_wb = bom_utils.create_scan2inv_format(
        output_data, output_wb, worksheet_name)
    output_wb.save(output)


def apply_categorize_rules_results(resources, rules_list):
    """
    Apply categorization and return the processed results
    """
    processed_resources = []
    for resource in resources:
        for rule_dict in rules_list:
            condition_list = rule_dict['condition'].split('\n')
            rule_list = rule_dict['rule'].split('\n')
            matched = False
            classname = ''
            order = ''
            analysis_priority = ''
            file_category = ''
            file_subcategory = ''
            for idx, condition in enumerate(condition_list):
                rule_type = condition.partition(':')[0].strip()
                rule = [r.strip()
                        for r in rule_list[idx].partition(':')[2].split(",")]
                rule_condition = condition.partition(':')[2].strip()
                value = getattr(resource, rule_type)
                if not validate_matching(value, rule_condition, rule):
                    matched = False
                    break
                else:
                    # Replace the file-cat data if the current rule's order
                    # is smaller
                    if hasattr(resource, 'order'):
                        if resource.order > rule_dict['order']:
                            classname = rule_dict['class']
                            order = rule_dict['order']
                            analysis_priority = rule_dict['analysis_priority']
                            file_category = rule_dict['file_category']
                            file_subcategory = rule_dict['file_subcategory']
                            matched = True
                    else:
                        classname = rule_dict['class']
                        order = rule_dict['order']
                        analysis_priority = rule_dict['analysis_priority']
                        file_category = rule_dict['file_category']
                        file_subcategory = rule_dict['file_subcategory']
                        matched = True
            if matched:
                resource.classname = classname
                resource.order = order
                resource.analysis_priority = analysis_priority
                resource.file_category = file_category
                resource.file_subcategory = file_subcategory
        processed_resources.append(resource)

    return processed_resources


def validate_matching(value, rule_condition, rules):
    """
    Check if value meet the rule's condition
    Return True if condition met, False otherwise
    Current supported condition:
     - in
     - substring
     - equal
     - startswith
     - endswith
     - boolean
    """
    if rule_condition == 'in':
        return value.lower() in rules
    elif rule_condition == 'substring':
        for rule in rules:
            if rule in value.lower():
                return True
    elif rule_condition == 'equal':
        for rule in rules:
            if value.lower() == rule:
                return True
    elif rule_condition == 'startswith':
        for rule in rules:
            if value.lower().startswith(rule.lower()):
                return True
    elif rule_condition == 'endswith':
        for rule in rules:
            if value.lower().endswith(rule.lower()):
                return True
    elif rule_condition == 'boolean':
        if rules == ['True']:
            if value:
                return True
            else:
                return False
        else:
            if value:
                return False
            else:
                return True
    else:
        # Print the condition that the tool doesn't know what to do
        print("NOT SUPPORTED CONDITION: " + rule_condition)

    return False
